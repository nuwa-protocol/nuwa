# NuwaScript Python Examples

This directory contains example scripts demonstrating the usage of the NuwaScript Python implementation.

## `generate_with_llm.py`

This example showcases how to integrate the NuwaScript interpreter with a Large Language Model (LLM), specifically OpenAI's API, to generate NuwaScript code from natural language requests.

### Purpose

The script demonstrates the following workflow:

1.  **Define Tools**: Sets up a `ToolRegistry` with sample tools (like `get_price`, `swap`, `reply`) and their schemas using `ToolSchema`.
2.  **Build Prompt**: Uses `nuwa.prompts.build_system_prompt` to automatically generate a system prompt for the LLM. This prompt includes the NuwaScript syntax specification and the detailed descriptions of the available tools derived from the registry.
3.  **Call LLM**: Takes a user's natural language request, sends it along with the system prompt to the OpenAI API (GPT-4o or similar).
4.  **Process Output**: Receives the LLM's response, which should ideally be NuwaScript code.
5.  **Validate & Execute**: Parses the generated script using `nuwa.parser` and executes it using `nuwa.interpreter` with the defined mock tools.

### Prerequisites

1.  **Python Environment**: Ensure you have Python 3.8+ installed. Using a virtual environment (`venv`) is highly recommended.
2.  **Install `nuwa-script`**: Make sure the core `nuwa-script` library is installed in your environment. If running from the cloned repository, navigate to `nuwa-script/implementations/python` and run:
    ```bash
    pip install -e .
    ```
3.  **Install `openai` Library**: This example uses the OpenAI API.
    ```bash
    pip install openai
    ```
4.  **OpenAI API Key**: You need an API key from OpenAI. Set it as an environment variable:
    ```bash
    export OPENAI_API_KEY='your-actual-api-key'
    ```
    Alternatively, you can modify the script to configure the `OpenAI()` client directly, but using environment variables is generally preferred.

### Running the Example

1.  Navigate to the `examples` directory:
    ```bash
    cd nuwa-script/implementations/python/examples
    ```
2.  Ensure your virtual environment (if used) is activated and the `OPENAI_API_KEY` environment variable is set.
3.  Run the script:
    ```bash
    python3 generate_with_llm.py
    # If you encounter 'No module named nuwa', ensure you are using python3
    # or that your virtual environment is active and `python` points to the correct interpreter.
    ```

### Expected Output

The script will:

1.  Print the generated "Available Tools" section of the prompt.
2.  Print the user request being sent to the LLM.
3.  Print the raw NuwaScript code generated by the LLM.
4.  Attempt to validate the generated script's syntax.
5.  If validation succeeds, attempt to execute the script using the mock tools, printing any output from the tools or the final interpreter state.
6.  If validation or execution fails, print the corresponding error message.

### Customization

*   **User Request**: Modify the `user_request` variable inside the `if __name__ == "__main__":` block to experiment with different natural language instructions.
*   **LLM Model**: Change the `model` parameter in the `client.chat.completions.create` call (e.g., to `"gpt-3.5-turbo"`) if desired.
*   **Tools**: Add, remove, or modify the tool functions and their `ToolSchema` definitions at the beginning of the script to change the capabilities available to the LLM. The prompt generation will adapt automatically.
*   **Prompt Engineering**: Edit the `TASK_DESCRIPTION` constant or add few-shot examples to the `build_system_prompt` call to refine the LLM's behavior.
